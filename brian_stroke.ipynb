mport os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, precision_score
from sklearn.model_selection import GridSearchCV
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import TomekLinks
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout

# Attention Layer
class AttentionLayer(tf.keras.layers.Layer):
    def _init_(self, **kwargs):
        super(AttentionLayer, self)._init_(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1), initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1), initializer="zeros")
        super(AttentionLayer, self).build(input_shape)

    def call(self, x):
        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)
        a = tf.keras.backend.softmax(e, axis=1)
        output = x * tf.keras.backend.repeat_elements(a, x.shape[-1], axis=2)
        return tf.keras.backend.sum(output, axis=1)
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

df = pd.read_csv("/content/brain_stroke.csv")
df.head()

df.duplicated().sum()
df.isna().sum()

cat = df[["gender", "hypertension", "heart_disease", "ever_married",
                       "work_type", "Residence_type", "smoking_status"]]
num = df[["age", "avg_glucose_level", "bmi"]]

cat.astype('object').describe()

# calculate descriptive statistics for 20<bmi<40
df[(df['bmi'] > 20) & (df['bmi'] < 40)].astype('object').describe()

df.drop(['hypertension','heart_disease'],axis=1,inplace=True)

df = pd.get_dummies(df, columns=['work_type', 'smoking_status'])
df.head()

label_encoder = LabelEncoder()

for i in ["gender", "ever_married", "Residence_type"]:
    df[i] = label_encoder.fit_transform(df[i])

df.head()
scaler = StandardScaler()

# Fit scaler on selected columns.
scaler.fit(num)

# Transform selected columns with scaler.
num_features = scaler.transform(num)

X = df.drop("stroke", axis=1)
y = df["stroke"]

# Split the data into train and test.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Split the train data into two subsets, train1 and test1
X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, test_size=0.25, random_state=10)

# Split the train data into two subsets, train2 and test2
X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.25, random_state=20)

# Instantiate the SMOTE class
smote = SMOTE(sampling_strategy='auto', random_state=42)

# Perform SMOTE oversampling on the dataset
X_overesampled, y_overesampled = smote.fit_resample(X_train1, y_train1)

## Initialize the models.(needs to be changed)
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000)
}##
# Model architecture
inputs = Input(shape=(X_train.shape[1], 1))
lstm_out = LSTM(32, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(inputs)
attention = AttentionLayer()(lstm_out)
dropout = Dropout(0.5)(attention)
output = Dense(1, activation='sigmoid')(dropout)
model = Model(inputs, output)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
X_train_reshaped = X_resampled.values.reshape(X_resampled.shape[0], X_resampled.shape[1], 1)
X_test_reshaped = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)
model.fit(X_train_reshaped, y_resampled, epochs=10, batch_size=64, validation_split=0.2)

# Iterate over each model and evaluate its accuracy using cross-validation.
for model_name, model in models.items():
    scores = cross_val_score(model, X_overesampled, y_overesampled)
    accuracy = scores.mean()
    print(f'{model_name} Accuracy: {accuracy}')

    # Fit the model to the full training set and make predictions on the test set
    model.fit(X_overesampled, y_overesampled)
    y_pred1 = model.predict(X_test1)

    # Evaluate the model on the test set
    acc = accuracy_score(y_test1, y_pred1)
    prec = precision_score(y_test1, y_pred1)

    print(f"Accuracy: {acc:.3f}")
    print(f"Precision: {prec:.3f}")
tomek_links = TomekLinks(sampling_strategy='auto', n_jobs=-1)

# Perform Tomek Links undersampling on the dataset
X_underesampled, y_underesampled = tomek_links.fit_resample(X_train2, y_train2)

X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Make tha Logistic Regression model.
logreg = LogisticRegression(C=10, penalty='l1')

# Fit the model.
model.fit(X_resampled, y_resampled)

# Predict y-predict.
# Evaluate
y_pred = (model.predict(X_test_reshaped) > 0.5).astype(int)
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)

print(f"Accuracy: {acc:.3f}")
print(f"Precision: {prec:.3f}")

